{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load extrated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run twitter_api.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from nltk import FreqDist\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo as hashtags e guardando em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_tweets.hashtags.apply(lambda x: np.nan if len(x) <= 0 else x)\n",
    "all_hashtags = list(data.dropna())\n",
    "all_hashtags[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de frequências de hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = []\n",
    "for i in all_hashtags:\n",
    "    for j in i:\n",
    "        hashtags.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_str = ''\n",
    "\n",
    "for i in hashtags:\n",
    "    hash_str += i + ' '\n",
    "\n",
    "hash_str = hash_str.lower()\n",
    "hashtags2 = hash_str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = FreqDist(hashtags2)\n",
    "hash_most_freq = pd.DataFrame(data = freq.most_common(10), columns = ['Hashtag', 'Frequency'])\n",
    "hash_most_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_freq = list(hash_most_freq.Hashtag)\n",
    "list_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funçao para comparar todas as hashtags dos tweets com a lista das mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_hashtag(freq, all_hash):\n",
    "    select = []\n",
    "    \n",
    "    for list_hash in all_hash:\n",
    "        for f in freq:\n",
    "            if (len(list_hash) >=2 and (f in list_hash)):\n",
    "                select.append(list_hash)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "    return select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def select_hashtag(freq, all_hash):\n",
    "    select = []\n",
    "    for f in freq:\n",
    "        for list_hash in all_hash:\n",
    "            if len(list_hash) >=2:\n",
    "                highest = process.extractOne(f, list_hash)\n",
    "                if highest[1] > 90:\n",
    "                    select.append(list_hash)\n",
    "                else:\n",
    "                    pass\n",
    "    return select \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtags filtradas: apenas aquelas que contenham alguma Hashtag frequente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda opçao, colocando todas as hashtags minúsculas (testando o resultado da comparaçao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtags_lower = [[h.lower() for h in line] for line in all_hashtags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_hashtags_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = select_hashtag(list_freq, all_hashtags_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica o algoritmo apriori, que retorna os itens frequentes na lista de hashtags. O parâmetro min_suport (0-1) \"regula\" o quanto um item é considerado \"frequente\" na lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(select).transform(select)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando associação usando \"metric=confidence\" (Fornece a probabilidade do consequente em uma transação, dada a presença de antecedente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rules=association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando associação usando \"metric=lift\" (Dado que antecedentes e consequentes são independentes, com que frequência eles se juntam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.antecedents = rules.antecedents.apply(lambda x: next(iter(x)))\n",
    "rules.consequents = rules.consequents.apply(lambda x: next(iter(x)))\n",
    "#rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando NetworkX para construir um gráfico para verificar a associação entre antecedentes e consequentes obtidos após a regra de associação aplicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(16,9))\n",
    "GA=nx.from_pandas_edgelist(rules,source='antecedents',target='consequents')\n",
    "nx.draw(GA,with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando os parâmetros para melhorar a visualização\n",
    "\n",
    "https://networkx.github.io/documentation/networkx-1.10/reference/drawing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(16,9))\n",
    "\n",
    "GA=nx.from_pandas_edgelist(rules,source='antecedents',target='consequents')\n",
    "\n",
    "pos = nx.spring_layout(GA)\n",
    "\n",
    "nx.draw_networkx(GA,pos,with_labels=False)\n",
    "\n",
    "nx.draw_networkx_edges(GA, pos, edgelist=None, width=2.0, edge_color='R', style='solid', alpha=1.0, edge_cmap=None, edge_vmin=None, edge_vmax=None, ax=None, arrows=True, label=None)\n",
    "\n",
    "#nx.draw_networkx_labels(GA, pos, labels=None, font_size=12, font_color='k', font_family='sans-serif', font_weight='normal', alpha=1.0, bbox=None, ax=None)\n",
    "\n",
    "nx.draw_networkx_nodes(GA, pos, nodelist=None, node_size=100, node_color='y', node_shape='o', alpha=1.0, cmap=None, vmin=None, vmax=None, ax=None, linewidths=None, label=None)\n",
    "\n",
    "text = nx.draw_networkx_labels(GA,pos)\n",
    "\n",
    "for _,t in text.items():\n",
    "    t.set_rotation('horizontal')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvconda9df388cab72442e9966696d7b0348bd5",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}