{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tweepy for Twitter API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter is one of the most accessed social networks in the world. Every type of company usually has an account. With that in mind, they are able to verify people's engagement with their products and services, in addition to being able to know their feelings about it. Thus, companies can increase or change their strategies in order to establish an improvement in their deliveries.\n",
    "\n",
    "[Tweepy](http://docs.tweepy.org/en/latest/) is an open source package of Python and an easy way to connect with the Twitter API to collect information, perform analysis and do some automations.\n",
    "\n",
    "Tweepy imposes a rate limit of frequency on the use of the API. Exceeding this limit, we will have to wait 15 minutes to use the API again.\n",
    "\n",
    "*Note: we're going to use Public Mode in our procedures.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is the objective here?**\n",
    "\n",
    "* Collect tweets and retweets.\n",
    "    * timestamp\n",
    "    * location of user\n",
    "    * (re)tweet text\n",
    "    * retweet count\n",
    "    * hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install tweepy package:\n",
    "\n",
    "```\n",
    "pip install tweepy\n",
    "```\n",
    "\n",
    "Alternatively, install directly from the GitHub repository:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/tweepy/tweepy.git\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTHENTICATION**\n",
    "\n",
    "``Private Mode`` - It needs *consumer key*, *consumer secret key*, *access token* and *access token secret.* It's used when, for exemple, you want to do almost everything you can do on the website using code. If you wants to tweet and retweet something, you can. If you want a bot account, you can. And so on...\n",
    "\n",
    "\n",
    "``Public Mode`` - It needs only *consumer key* and *consumer secret key.* The user only access public information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keys reading\n",
    "\n",
    "# We saved the keys/tokens on a plain text file to \"hide\" them.\n",
    "# HERE WE´RE NOT GOING TO USE TOKEN/TOKEN SECRET\n",
    "\n",
    "with open('twtk.txt', 'r') as file:\n",
    "    CONSUMER_KEY = file.readline().strip('\\n')\n",
    "    CONSUMER_SECRET_KEY = file.readline().strip('\\n')\n",
    "\n",
    "## Connect the consumer key\n",
    "\n",
    "auth = tw.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET_KEY) # To both Private and Public Modes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONNECTION TO TWITTER API**\n",
    "\n",
    "We use the ``auth`` to connect the API. Here are some parameters, among others, to check:\n",
    "\n",
    "* ``wait_on_rate_limit``. When we exceed the rate limit, the connection can be kept if 'True', waiting the API allows procedures again. If 'False', the connection is lost.\n",
    "* ``wait_on_rate_limit_notify`` notifies when the limit is exceeded and the api is waiting for rate limits to replenish.\n",
    "* ``timeout`` is the maximum amount of time (in seconds) to wait for a response from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access API user\n",
    "api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLLECT TWEETS**\n",
    "\n",
    "- `api.search`: returns a collection of relevant Tweets matching a specified query;\n",
    "- `q`: any word or list of words we want to check;\n",
    "- `lang`: language given by an ISO 639-1 code;\n",
    "- `result_type`:\n",
    "\n",
    "    - *mixed*: include both popular and real time results in the response;\n",
    "    - *recent*: return only the most recent results in the response;\n",
    "    - *popular*: return only the most popular results in the response.\n",
    "    \n",
    "- `tweet_mode`: if 'compatibility', it returns the until 140 characters. If  'extended', over 140 characters.\n",
    "\n",
    "You can use Cursor attributes:\n",
    "- ``.items(x)`` returns a specific 'x' quantity of tweets;\n",
    "- ``.pages(x)`` returns a specific 'x' quantity of pages (usually about few dozen items).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters\n",
    "\n",
    "# Twitter\n",
    "QUERY1 = ['datascience OR machinelearning OR neuralnetwork']\n",
    "ITEMS = 1000\n",
    "\n",
    "# lists\n",
    "\n",
    "RETWEETS = []\n",
    "TWEETS = []\n",
    "\n",
    "# The next loop for collects tweets and retweets according to ITEMS \n",
    "# defined. Note that quantity for each tweet and retweet will be less \n",
    "# than ITEMS. \n",
    "\n",
    "# Here we're not using filter on query previously due to the own loop\n",
    "# has if statement segregating both tweet and retweet\n",
    "\n",
    "for tweet in tw.Cursor(api.search,\n",
    "                    q= QUERY1, \n",
    "                    lang= 'pt',\n",
    "                    result_type='recent',\n",
    "                    tweet_mode = 'extended'  # collect the full text (over 140 characters)\n",
    "                    ).items(ITEMS):\n",
    "\n",
    "                    if (tweet.retweeted) or ('RT @' in tweet.full_text):\n",
    "\n",
    "                        RETWEETS.append([tweet.created_at, tweet.user.location, tweet.full_text.replace('\\n', ' '), \n",
    "                                          tweet.retweet_count, [e['text'] for e in tweet._json['entities']['hashtags']]])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        TWEETS.append([tweet.created_at, tweet.user.location, tweet.full_text.replace('\\n', ' '), \n",
    "                                          tweet.retweet_count, [e['text'] for e in tweet._json['entities']['hashtags']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting tweets on a Data Frame for better view\n",
    "\n",
    "df_tweets = pd.DataFrame(data=TWEETS,  columns=[ 'created_at', \"location\", 'tweet_text','retweet_count', 'hashtags'])\n",
    "df_retweets = pd.DataFrame(data=RETWEETS,  columns=['created_at', \"location\", 'tweet_text','retweet_count', 'hashtags'])\n",
    "\n",
    "## Saving on .csv file\n",
    "df_tweets.to_csv('tweets.csv', index=0)\n",
    "df_retweets.to_csv('retweets.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-11 20:05:40</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>A busca pela vantagem competitiva, novos conhe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Deloitte, DataScience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11 20:00:01</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>A busca pela vantagem competitiva, por conheci...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Deloitte, DataScience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-11 17:52:13</td>\n",
       "      <td>São Paulo-SP</td>\n",
       "      <td>#vemprawayon #vagasti #cientistadedados #R #Py...</td>\n",
       "      <td>0</td>\n",
       "      <td>[vemprawayon, vagasti, cientistadedados, R, Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-11 16:52:34</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Tudo menos isso. #machinelearning https://t.co...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machinelearning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-11 16:09:06</td>\n",
       "      <td></td>\n",
       "      <td>Estamos ficando velho! 2017 - primeira conferê...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tbt, botsbrasil, bots, machinelearning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-11 16:03:59</td>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>Pense na molecada preta voando em #Pandas, em ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pandas, NumPy, MachineLearning, AI, Matplotli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-11 15:34:43</td>\n",
       "      <td></td>\n",
       "      <td>Facebook AI fez um modelo não supervisionado p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[deeplearning, machinelearning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-11 15:34:16</td>\n",
       "      <td>BH, MG, Brasil</td>\n",
       "      <td>As 10 tendências em dados e analytics para sup...</td>\n",
       "      <td>1</td>\n",
       "      <td>[COVID19, BigData, Analytics, AI, DataScience,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-11 15:29:49</td>\n",
       "      <td>Belém-PA</td>\n",
       "      <td>Pouco espaço mas a gente da um jeito. Seguindo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[DataScience, PythonProgramming, DataAnalytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-11 15:15:23</td>\n",
       "      <td>Somewhere over the Mid-Pacific</td>\n",
       "      <td>Existem oportunidades para estrangeiros trabal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[datascience, Brasil]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                        location  \\\n",
       "0 2020-06-11 20:05:40                          Brasil   \n",
       "1 2020-06-11 20:00:01                          Brasil   \n",
       "2 2020-06-11 17:52:13                    São Paulo-SP   \n",
       "3 2020-06-11 16:52:34                       São Paulo   \n",
       "4 2020-06-11 16:09:06                                   \n",
       "5 2020-06-11 16:03:59          Rio de Janeiro, Brasil   \n",
       "6 2020-06-11 15:34:43                                   \n",
       "7 2020-06-11 15:34:16                  BH, MG, Brasil   \n",
       "8 2020-06-11 15:29:49                        Belém-PA   \n",
       "9 2020-06-11 15:15:23  Somewhere over the Mid-Pacific   \n",
       "\n",
       "                                          tweet_text  retweet_count  \\\n",
       "0  A busca pela vantagem competitiva, novos conhe...              0   \n",
       "1  A busca pela vantagem competitiva, por conheci...              0   \n",
       "2  #vemprawayon #vagasti #cientistadedados #R #Py...              0   \n",
       "3  Tudo menos isso. #machinelearning https://t.co...              2   \n",
       "4  Estamos ficando velho! 2017 - primeira conferê...              0   \n",
       "5  Pense na molecada preta voando em #Pandas, em ...              0   \n",
       "6  Facebook AI fez um modelo não supervisionado p...              1   \n",
       "7  As 10 tendências em dados e analytics para sup...              1   \n",
       "8  Pouco espaço mas a gente da um jeito. Seguindo...              1   \n",
       "9  Existem oportunidades para estrangeiros trabal...              0   \n",
       "\n",
       "                                            hashtags  \n",
       "0                            [Deloitte, DataScience]  \n",
       "1                            [Deloitte, DataScience]  \n",
       "2  [vemprawayon, vagasti, cientistadedados, R, Py...  \n",
       "3                                  [machinelearning]  \n",
       "4           [tbt, botsbrasil, bots, machinelearning]  \n",
       "5  [Pandas, NumPy, MachineLearning, AI, Matplotli...  \n",
       "6                    [deeplearning, machinelearning]  \n",
       "7  [COVID19, BigData, Analytics, AI, DataScience,...  \n",
       "8  [DataScience, PythonProgramming, DataAnalytics...  \n",
       "9                              [datascience, Brasil]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-11 19:26:32</td>\n",
       "      <td></td>\n",
       "      <td>RT @ofelipeb: Pense na molecada preta voando e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pandas, NumPy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11 18:53:01</td>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>RT @DMSS_Software: De pesquisa de mercado até ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-11 17:26:06</td>\n",
       "      <td>Paris, France 🇫🇷</td>\n",
       "      <td>RT @SaudenoBR: Tudo menos isso. #machinelearni...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machinelearning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-11 17:14:00</td>\n",
       "      <td></td>\n",
       "      <td>RT @SaudenoBR: Tudo menos isso. #machinelearni...</td>\n",
       "      <td>2</td>\n",
       "      <td>[machinelearning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-11 16:36:50</td>\n",
       "      <td>Benito Juárez</td>\n",
       "      <td>RT @marcusbhz: As 10 tendências em dados e ana...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-11 16:25:11</td>\n",
       "      <td>Benito Juárez</td>\n",
       "      <td>RT @ric_med: Pouco espaço mas a gente da um je...</td>\n",
       "      <td>1</td>\n",
       "      <td>[DataScience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-11 15:54:45</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>RT @IPTSP: O encontro acontece no dia 12 de ju...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-11 13:56:47</td>\n",
       "      <td></td>\n",
       "      <td>RT @marcusborba: Join me at #SAPPHIRENOW  Regi...</td>\n",
       "      <td>12</td>\n",
       "      <td>[SAPPHIRENOW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-11 11:50:35</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>RT @marcusborba: Join me at #SAPPHIRENOW  Regi...</td>\n",
       "      <td>12</td>\n",
       "      <td>[SAPPHIRENOW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-11 11:49:34</td>\n",
       "      <td></td>\n",
       "      <td>RT @marcusborba: Join me at #SAPPHIRENOW  Regi...</td>\n",
       "      <td>12</td>\n",
       "      <td>[SAPPHIRENOW]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at           location  \\\n",
       "0 2020-06-11 19:26:32                      \n",
       "1 2020-06-11 18:53:01  São Paulo, Brasil   \n",
       "2 2020-06-11 17:26:06   Paris, France 🇫🇷   \n",
       "3 2020-06-11 17:14:00                      \n",
       "4 2020-06-11 16:36:50      Benito Juárez   \n",
       "5 2020-06-11 16:25:11      Benito Juárez   \n",
       "6 2020-06-11 15:54:45          São Paulo   \n",
       "7 2020-06-11 13:56:47                      \n",
       "8 2020-06-11 11:50:35            Bedford   \n",
       "9 2020-06-11 11:49:34                      \n",
       "\n",
       "                                          tweet_text  retweet_count  \\\n",
       "0  RT @ofelipeb: Pense na molecada preta voando e...              0   \n",
       "1  RT @DMSS_Software: De pesquisa de mercado até ...              2   \n",
       "2  RT @SaudenoBR: Tudo menos isso. #machinelearni...              2   \n",
       "3  RT @SaudenoBR: Tudo menos isso. #machinelearni...              2   \n",
       "4  RT @marcusbhz: As 10 tendências em dados e ana...              1   \n",
       "5  RT @ric_med: Pouco espaço mas a gente da um je...              1   \n",
       "6  RT @IPTSP: O encontro acontece no dia 12 de ju...              1   \n",
       "7  RT @marcusborba: Join me at #SAPPHIRENOW  Regi...             12   \n",
       "8  RT @marcusborba: Join me at #SAPPHIRENOW  Regi...             12   \n",
       "9  RT @marcusborba: Join me at #SAPPHIRENOW  Regi...             12   \n",
       "\n",
       "            hashtags  \n",
       "0    [Pandas, NumPy]  \n",
       "1                 []  \n",
       "2  [machinelearning]  \n",
       "3  [machinelearning]  \n",
       "4                 []  \n",
       "5      [DataScience]  \n",
       "6                 []  \n",
       "7      [SAPPHIRENOW]  \n",
       "8      [SAPPHIRENOW]  \n",
       "9      [SAPPHIRENOW]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a simple way to collect some (re)tweets informations.\n",
    "\n",
    "Hope you enjoyed.\n",
    "\n",
    "**Timão Legal** :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}